# Analyzing the Vulnerability of Machine Learning Models against Membership Inference Attacks

In this project, we are implementing the membership inference attack on a neural network model built on the Fashion MNIST image dataset. 
For the implementation of this attack, we are following the Shadow Model Training technique proposed by Shokri et al.  

## Team
|Student name| CCID |
|------------|------|
|Chirag Daryani   |  cdaryani    |
|Karan Chadha   |  kchadha1    |

## Code Files

1.Effect_of_Changing_Attack_Model_Architecture.ipynb
2.Effect_of_Changing_No_of_Classes.ipynb
3.Effect_of_Overfitting_and_Dropout.ipynb

## References

https://cloudxlab.com/blog/fashion-mnist-using-deep-learning-with-tensorflow-keras/
https://github.com/cloudxlab/ml/blob/master/projects/Fashion-MNIST/Fashion-MNIST-DL-Keras.ipynb
https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/
https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/
